{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c192a04e-26c7-4a8f-9119-df16808be85e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c192a04e-26c7-4a8f-9119-df16808be85e",
        "outputId": "372cf2ca-9a28-401b-9ab4-57567ca6738d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['store', 'process', 'provide', 'providing', 'improve', 'indicated']\n",
            "['store', 'process']\n",
            "\n",
            "Using the 'dep' visualizer\n",
            "Serving on http://0.0.0.0:5000 ...\n",
            "\n",
            "Shutting down server on port 5000.\n",
            "Dependency parser correctly identified the verbs.\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "def process_sentence(input_sentence, ground_truth_actions, verbose=False, visualize=False):\n",
        "    # Load the English language model\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    # Process the sentence using spaCy\n",
        "    doc = nlp(input_sentence)\n",
        "    detected_verbs = []\n",
        "\n",
        "    # Print the tokens and their dependencies\n",
        "    for token in doc:\n",
        "        if token.pos_ == \"VERB\":\n",
        "            detected_verbs.append(token.text)\n",
        "    if verbose == True:\n",
        "      print(detected_verbs)\n",
        "      print(ground_truth_actions)\n",
        "\n",
        "    if (verbose == True):\n",
        "      spacy.displacy.serve(doc, style=\"dep\", auto_select_port=True)\n",
        "    # Compare detected verbs with ground truth actions\n",
        "    if set(ground_truth_actions).issubset(detected_verbs):\n",
        "        print(\"Dependency parser correctly identified the verbs.\")\n",
        "    else:\n",
        "        print(\"Dependency parser did not identify the verbs as expected.\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Input sentence\n",
        "    sentence = \"We may store and process your personal data you provide through the usage of the app and through the account creation process solely for the purpose of providing services to you, to improve our service features and other purposes indicated in this Privacy Policy.\"\n",
        "    ground_truth_action = ['store', 'process']\n",
        "\n",
        "    # Process the sentence\n",
        "    process_sentence(sentence, ground_truth_action, True)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parser Code with Example Runs"
      ],
      "metadata": {
        "id": "DS4FQXXi0HSc"
      },
      "id": "DS4FQXXi0HSc"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "67b7d141-1ed3-4af2-98fc-b5f95911eb9e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67b7d141-1ed3-4af2-98fc-b5f95911eb9e",
        "outputId": "763b0f25-e7e3-4be6-f55c-d6ec31b7c806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation for sentence 1:\n",
            "Detected Verbs: {'provide', 'process', 'improve', 'store', 'providing', 'indicated'}\n",
            "Detected Verbs with disjointed elements substitution : [0, 'process', 0, 'store', 0, 0]\n",
            "Ground Truth Actions: ['store', 'process']\n",
            "Accuracy: 1.00\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1-score: 1.00\n",
            "\n",
            "Evaluation for sentence 2:\n",
            "Detected Verbs: {'improve', 'provide'}\n",
            "Detected Verbs with disjointed elements substitution : ['improve', 'provide']\n",
            "Ground Truth Actions: ['provide', 'improve']\n",
            "Accuracy: 1.00\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1-score: 1.00\n",
            "\n",
            "Evaluation for sentence 3:\n",
            "Detected Verbs: {'create', 'indicated', 'follow'}\n",
            "Detected Verbs with disjointed elements substitution : ['create', 'indicated', 0]\n",
            "Ground Truth Actions: ['create', 'indicated']\n",
            "Accuracy: 1.00\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1-score: 1.00\n",
            "\n",
            "Consolidated Performance Metrics:\n",
            "Average Accuracy: 1.00\n",
            "Average Precision: 1.00\n",
            "Average Recall: 1.00\n",
            "Average F1-score: 1.00\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def process_sentence(input_sentence, ground_truth_actions):\n",
        "    # Load the English language model\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    # Process the sentence using spaCy\n",
        "    doc = nlp(input_sentence)\n",
        "\n",
        "    # Collect verbs identified by the dependency parser\n",
        "    detected_verbs = set()\n",
        "    for token in doc:\n",
        "        if token.pos_ == \"VERB\":\n",
        "            detected_verbs.add(token.text)\n",
        "\n",
        "    # Retain only the verbs present in ground_truth_actions\n",
        "    detected_verbs_substituted = [verb if verb in ground_truth_actions else 0 for verb in detected_verbs]\n",
        "\n",
        "    return detected_verbs, detected_verbs_substituted\n",
        "\n",
        "def evaluate_performance(ground_truth_actions, detected_verbs):\n",
        "    # Replace 0s in detected_verbs with empty strings\n",
        "    detected_verbs_cleaned = [verb if verb != 0 else '' for verb in detected_verbs]\n",
        "\n",
        "    # Remove empty strings from the list\n",
        "    detected_verbs_cleaned = [verb for verb in detected_verbs_cleaned if verb != '']\n",
        "\n",
        "    while (len(detected_verbs_cleaned) != len(ground_truth_actions)):\n",
        "      detected_verbs_cleaned.append('0')\n",
        "\n",
        "    detected_verbs_cleaned = sorted(detected_verbs_cleaned)\n",
        "    ground_truth_actions = sorted(ground_truth_actions)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy = accuracy_score(ground_truth_actions, detected_verbs_cleaned)\n",
        "    precision = precision_score(ground_truth_actions, detected_verbs_cleaned, average='micro')\n",
        "    recall = recall_score(ground_truth_actions, detected_verbs_cleaned, average='micro')\n",
        "    f1 = f1_score(ground_truth_actions, detected_verbs_cleaned, average='micro')\n",
        "\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "def evaluate(sentences, ground_truth_actions_list):\n",
        "  accuracies = []\n",
        "  precisions = []\n",
        "  recall_scores = []\n",
        "  f1_scores = []\n",
        "  # Evaluate performance for each sentence\n",
        "  for idx, sentence in enumerate(sentences):\n",
        "      print(f\"\\nEvaluation for sentence {idx + 1}:\")\n",
        "      ground_truth_actions = ground_truth_actions_list[idx]\n",
        "\n",
        "      detected_verbs, detected_verbs_substituted = process_sentence(sentence, ground_truth_actions)\n",
        "\n",
        "      accuracy, precision, recall, f1 = evaluate_performance(ground_truth_actions, detected_verbs_substituted)\n",
        "\n",
        "      accuracies.append(accuracy)\n",
        "      precisions.append(precision)\n",
        "      recall_scores.append(recall)\n",
        "      f1_scores.append(f1)\n",
        "\n",
        "      print(f\"Detected Verbs: {detected_verbs}\")\n",
        "      print(f\"Detected Verbs with disjointed elements substitution : {detected_verbs_substituted}\")\n",
        "      print(f\"Ground Truth Actions: {ground_truth_actions}\")\n",
        "      print(f\"Accuracy: {accuracy:.2f}\")\n",
        "      print(f\"Precision: {precision:.2f}\")\n",
        "      print(f\"Recall: {recall:.2f}\")\n",
        "      print(f\"F1-score: {f1:.2f}\")\n",
        "    # Calculate average performance metrics\n",
        "  avg_accuracy = sum(accuracies) / len(accuracies)\n",
        "  avg_precision = sum(precisions) / len(precisions)\n",
        "  avg_recall = sum(recall_scores) / len(recall_scores)\n",
        "  avg_f1 = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "  print(\"\\nConsolidated Performance Metrics:\")\n",
        "  print(f\"Average Accuracy: {avg_accuracy:.2f}\")\n",
        "  print(f\"Average Precision: {avg_precision:.2f}\")\n",
        "  print(f\"Average Recall: {avg_recall:.2f}\")\n",
        "  print(f\"Average F1-score: {avg_f1:.2f}\")\n",
        "\n",
        "def main():\n",
        "    # Ground truth actions for each sentence\n",
        "    ground_truth_actions_list = [['store', 'process'], ['provide', 'improve'], ['create', 'indicated']]\n",
        "\n",
        "    # Input sentences\n",
        "    sentences = [\n",
        "        \"We may store and process your personal data you provide through the usage of the app and through the account creation process solely for the purpose of providing services to you, to improve our service features and other purposes indicated in this Privacy Policy.\",\n",
        "        \"The company will provide training to employees to improve their skills.\",\n",
        "        \"Please follow the instructions indicated on the screen to create a new account.\"\n",
        "    ]\n",
        "    evaluate(sentences, ground_truth_actions_list)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yunik's Experiments"
      ],
      "metadata": {
        "id": "yMsWT3bg0SER"
      },
      "id": "yMsWT3bg0SER"
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth_actions_list = [['store', 'process'],\n",
        "                             ['provide', 'improve'],\n",
        "                             ['create', 'indicated'],\n",
        "                             ['steal', 'info']]\n",
        "\n",
        "# Input sentences\n",
        "sentences = [\n",
        "        \"We may store and process your personal data you provide through the usage of the app and through the account creation process solely for the purpose of providing services to you, to improve our service features and other purposes indicated in this Privacy Policy.\",\n",
        "        \"The company will provide training to employees to improve their skills.\",\n",
        "        \"Please follow the instructions indicated on the screen to create a new account.\",\n",
        "        \"We steal your info\"\n",
        "]\n",
        "evaluate(sentences, ground_truth_actions_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy01gXTTyW5b",
        "outputId": "e661b3a9-d42b-4a97-e5df-125f7f5cae9f"
      },
      "id": "Dy01gXTTyW5b",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation for sentence 1:\n",
            "Detected Verbs: {'provide', 'process', 'improve', 'store', 'providing', 'indicated'}\n",
            "Detected Verbs with disjointed elements substitution : [0, 'process', 0, 'store', 0, 0]\n",
            "Ground Truth Actions: ['store', 'process']\n",
            "Accuracy: 1.00\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1-score: 1.00\n",
            "\n",
            "Evaluation for sentence 2:\n",
            "Detected Verbs: {'improve', 'provide'}\n",
            "Detected Verbs with disjointed elements substitution : ['improve', 'provide']\n",
            "Ground Truth Actions: ['provide', 'improve']\n",
            "Accuracy: 1.00\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1-score: 1.00\n",
            "\n",
            "Evaluation for sentence 3:\n",
            "Detected Verbs: {'create', 'indicated', 'follow'}\n",
            "Detected Verbs with disjointed elements substitution : ['create', 'indicated', 0]\n",
            "Ground Truth Actions: ['create', 'indicated']\n",
            "Accuracy: 1.00\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1-score: 1.00\n",
            "\n",
            "Evaluation for sentence 4:\n",
            "Detected Verbs: {'steal'}\n",
            "Detected Verbs with disjointed elements substitution : ['steal']\n",
            "Ground Truth Actions: ['steal', 'info']\n",
            "Accuracy: 0.50\n",
            "Precision: 0.50\n",
            "Recall: 0.50\n",
            "F1-score: 0.50\n",
            "\n",
            "Consolidated Performance Metrics:\n",
            "Average Accuracy: 0.88\n",
            "Average Precision: 0.88\n",
            "Average Recall: 0.88\n",
            "Average F1-score: 0.88\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}